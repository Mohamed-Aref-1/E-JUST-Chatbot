{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "18hsPWHvDdFQ0v4HDw-skbrUNXVcuBdYe",
      "authorship_tag": "ABX9TyPAL9J60MDXODQf2rjrN2B3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mohamed-Aref-1/E-JUST-Chatbot/blob/main/Rasa_football_nlu_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93oAHnGrT2lX",
        "outputId": "43ce03e1-e832-4217-dde5-08e53dfb2c7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libstd-rust-1.75 libstd-rust-dev\n",
            "Suggested packages:\n",
            "  cargo llvm-17 lld-17 clang-17\n",
            "The following NEW packages will be installed:\n",
            "  libstd-rust-1.75 libstd-rust-dev rustc\n",
            "0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 91.4 MB of archives.\n",
            "After this operation, 369 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libstd-rust-1.75 amd64 1.75.0+dfsg0ubuntu1~bpo0-0ubuntu0.22.04 [46.3 MB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libstd-rust-dev amd64 1.75.0+dfsg0ubuntu1~bpo0-0ubuntu0.22.04 [41.6 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 rustc amd64 1.75.0+dfsg0ubuntu1~bpo0-0ubuntu0.22.04 [3,404 kB]\n",
            "Fetched 91.4 MB in 3s (30.3 MB/s)\n",
            "Selecting previously unselected package libstd-rust-1.75:amd64.\n",
            "(Reading database ... 121752 files and directories currently installed.)\n",
            "Preparing to unpack .../libstd-rust-1.75_1.75.0+dfsg0ubuntu1~bpo0-0ubuntu0.22.04_amd64.deb ...\n",
            "Unpacking libstd-rust-1.75:amd64 (1.75.0+dfsg0ubuntu1~bpo0-0ubuntu0.22.04) ...\n",
            "Selecting previously unselected package libstd-rust-dev:amd64.\n",
            "Preparing to unpack .../libstd-rust-dev_1.75.0+dfsg0ubuntu1~bpo0-0ubuntu0.22.04_amd64.deb ...\n",
            "Unpacking libstd-rust-dev:amd64 (1.75.0+dfsg0ubuntu1~bpo0-0ubuntu0.22.04) ...\n",
            "Selecting previously unselected package rustc.\n",
            "Preparing to unpack .../rustc_1.75.0+dfsg0ubuntu1~bpo0-0ubuntu0.22.04_amd64.deb ...\n",
            "Unpacking rustc (1.75.0+dfsg0ubuntu1~bpo0-0ubuntu0.22.04) ...\n",
            "Setting up libstd-rust-1.75:amd64 (1.75.0+dfsg0ubuntu1~bpo0-0ubuntu0.22.04) ...\n",
            "Setting up libstd-rust-dev:amd64 (1.75.0+dfsg0ubuntu1~bpo0-0ubuntu0.22.04) ...\n",
            "Setting up rustc (1.75.0+dfsg0ubuntu1~bpo0-0ubuntu0.22.04) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  cargo-doc\n",
            "The following NEW packages will be installed:\n",
            "  cargo\n",
            "0 upgraded, 1 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 6,700 kB of archives.\n",
            "After this operation, 23.3 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 cargo amd64 1.75.0+dfsg0ubuntu1~bpo0-0ubuntu0.22.04 [6,700 kB]\n",
            "Fetched 6,700 kB in 1s (8,253 kB/s)\n",
            "Selecting previously unselected package cargo.\n",
            "(Reading database ... 121827 files and directories currently installed.)\n",
            "Preparing to unpack .../cargo_1.75.0+dfsg0ubuntu1~bpo0-0ubuntu0.22.04_amd64.deb ...\n",
            "Unpacking cargo (1.75.0+dfsg0ubuntu1~bpo0-0ubuntu0.22.04) ...\n",
            "Setting up cargo (1.75.0+dfsg0ubuntu1~bpo0-0ubuntu0.22.04) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "!apt install rustc && apt install cargo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasa[transformers]==3.6.15\n",
        "!pip install nest-asyncio==1.5.6\n",
        "!pip install --upgrade ipykernel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P76BJqeIUOWw",
        "outputId": "8193aeea-e8b9-40c8-ec1e-932db0d03403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasa[transformers]==3.6.15\n",
            "  Downloading rasa-3.6.15-py3-none-any.whl (837 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m837.9/837.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting CacheControl<0.13.0,>=0.12.9 (from rasa[transformers]==3.6.15)\n",
            "  Downloading CacheControl-0.12.14-py2.py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: PyJWT[crypto]<3.0.0,>=2.0.0 in /usr/lib/python3/dist-packages (from rasa[transformers]==3.6.15) (2.3.0)\n",
            "Collecting SQLAlchemy<1.5.0,>=1.4.0 (from rasa[transformers]==3.6.15)\n",
            "  Downloading SQLAlchemy-1.4.52-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py<1.5,>=0.9 in /usr/local/lib/python3.10/dist-packages (from rasa[transformers]==3.6.15) (1.4.0)\n",
            "Collecting aio-pika<8.2.4,>=6.7.1 (from rasa[transformers]==3.6.15)\n",
            "  Downloading aio_pika-8.2.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiogram<2.26 (from rasa[transformers]==3.6.15)\n",
            "  Downloading aiogram-2.25.2-py3-none-any.whl (203 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.5/203.5 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp!=3.7.4.post0,<3.9,>=3.6 (from rasa[transformers]==3.6.15)\n",
            "  Downloading aiohttp-3.8.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting apscheduler<3.10,>=3.6 (from rasa[transformers]==3.6.15)\n",
            "  Downloading APScheduler-3.9.1.post1-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting attrs<22.2,>=19.3 (from rasa[transformers]==3.6.15)\n",
            "  Downloading attrs-22.1.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3<2.0.0,>=1.26.136 (from rasa[transformers]==3.6.15)\n",
            "  Downloading boto3-1.34.92-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from rasa[transformers]==3.6.15) (2024.2.2)\n",
            "Requirement already satisfied: cloudpickle<2.3,>=1.2 in /usr/local/lib/python3.10/dist-packages (from rasa[transformers]==3.6.15) (2.2.1)\n",
            "Collecting colorclass<2.3,>=2.2 (from rasa[transformers]==3.6.15)\n",
            "  Downloading colorclass-2.2.2-py2.py3-none-any.whl (18 kB)\n",
            "Collecting coloredlogs<16,>=10 (from rasa[transformers]==3.6.15)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorhash<1.3.0,>=1.0.2 (from rasa[transformers]==3.6.15)\n",
            "  Downloading colorhash-1.2.1-py3-none-any.whl (5.7 kB)\n",
            "Collecting confluent-kafka<3.0.0,>=1.9.2 (from rasa[transformers]==3.6.15)\n",
            "  Downloading confluent_kafka-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=41.0.2 in /usr/local/lib/python3.10/dist-packages (from rasa[transformers]==3.6.15) (42.0.5)\n",
            "Collecting dask==2022.10.2 (from rasa[transformers]==3.6.15)\n",
            "  Downloading dask-2022.10.2-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dnspython==2.3.0 (from rasa[transformers]==3.6.15)\n",
            "  Downloading dnspython-2.3.0-py3-none-any.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fbmessenger<6.1.0,>=6.0.0 (from rasa[transformers]==3.6.15)\n",
            "  Downloading fbmessenger-6.0.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: google-auth<3 in /usr/local/lib/python3.10/dist-packages (from rasa[transformers]==3.6.15) (2.27.0)\n",
            "Collecting joblib<1.3.0,>=0.15.1 (from rasa[transformers]==3.6.15)\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonpickle<3.1,>=1.3 in /usr/local/lib/python3.10/dist-packages (from rasa[transformers]==3.6.15) (3.0.4)\n",
            "Collecting jsonschema<4.18,>=3.2 (from rasa[transformers]==3.6.15)\n",
            "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/90.4 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib<3.6,>=3.1 (from rasa[transformers]==3.6.15)\n",
            "  Downloading matplotlib-3.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mattermostwrapper<2.3,>=2.2 (from rasa[transformers]==3.6.15)\n",
            "  Downloading mattermostwrapper-2.2.tar.gz (2.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting networkx<2.7,>=2.4 (from rasa[transformers]==3.6.15)\n",
            "  Downloading networkx-2.6.3-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy<1.25.0,>=1.19.2 (from rasa[transformers]==3.6.15)\n",
            "  Downloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging<21.0,>=20.0 (from rasa[transformers]==3.6.15)\n",
            "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pluggy<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from rasa[transformers]==3.6.15) (1.5.0)\n",
            "Collecting portalocker<3.0.0,>=2.7.0 (from rasa[transformers]==3.6.15)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Collecting prompt-toolkit<3.0.29,>=3.0 (from rasa[transformers]==3.6.15)\n",
            "  Downloading prompt_toolkit-3.0.28-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.2/380.2 kB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf<4.23.4,>=4.23.3 (from rasa[transformers]==3.6.15)\n",
            "  Downloading protobuf-4.23.3-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting psycopg2-binary<2.10.0,>=2.8.2 (from rasa[transformers]==3.6.15)\n",
            "  Downloading psycopg2_binary-2.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic<1.10.10 (from rasa[transformers]==3.6.15)\n",
            "  Downloading pydantic-1.10.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydot<1.5,>=1.4 in /usr/local/lib/python3.10/dist-packages (from rasa[transformers]==3.6.15) (1.4.2)\n",
            "Collecting pykwalify<1.9,>=1.7 (from rasa[transformers]==3.6.15)\n",
            "  Downloading pykwalify-1.8.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting pymongo[srv,tls]<4.4,>=3.8 (from rasa[transformers]==3.6.15)\n",
            "  Downloading pymongo-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (492 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.9/492.9 kB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<2.9,>=2.8 in /usr/local/lib/python3.10/dist-packages (from rasa[transformers]==3.6.15) (2.8.2)\n",
            "Collecting python-engineio!=5.0.0,<6,>=4 (from rasa[transformers]==3.6.15)\n",
            "  Downloading python_engineio-4.9.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-socketio<6,>=4.4 (from rasa[transformers]==3.6.15)\n",
            "  Downloading python_socketio-5.11.2-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytz<2023.0,>=2019.1 (from rasa[transformers]==3.6.15)\n",
            "  Downloading pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.4/499.4 kB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.10/dist-packages (from rasa[transformers]==3.6.15) (6.0.1)\n",
            "Collecting questionary<1.11.0,>=1.5.1 (from rasa[transformers]==3.6.15)\n",
            "  Downloading questionary-1.10.0-py3-none-any.whl (31 kB)\n",
            "Collecting randomname<0.2.0,>=0.1.5 (from rasa[transformers]==3.6.15)\n",
            "  Downloading randomname-0.1.5.tar.gz (36 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting rasa-sdk<3.7.0,>=3.6.2 (from rasa[transformers]==3.6.15)\n",
            "  Downloading rasa_sdk-3.6.2-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting redis<5.0,>=4.5.3 (from rasa[transformers]==3.6.15)\n",
            "  Downloading redis-4.6.0-py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.1/241.1 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting regex<2022.11,>=2020.6 (from rasa[transformers]==3.6.15)\n",
            "  Downloading regex-2022.10.31-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (770 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m770.5/770.5 kB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3.0,>=2.23 in /usr/local/lib/python3.10/dist-packages (from rasa[transformers]==3.6.15) (2.31.0)\n",
            "Collecting rocketchat_API<1.31.0,>=0.6.31 (from rasa[transformers]==3.6.15)\n",
            "  Downloading rocketchat_API-1.30.0-py3-none-any.whl (21 kB)\n",
            "Collecting ruamel.yaml<0.17.22,>=0.16.5 (from rasa[transformers]==3.6.15)\n",
            "  Downloading ruamel.yaml-0.17.21-py3-none-any.whl (109 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sanic<21.13,>=21.12 (from rasa[transformers]==3.6.15)\n",
            "  Downloading sanic-21.12.2-py3-none-any.whl (156 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sanic-cors<2.1.0,>=2.0.0 (from rasa[transformers]==3.6.15)\n",
            "  Downloading Sanic_Cors-2.0.1-py2.py3-none-any.whl (17 kB)\n",
            "Collecting sanic-jwt<2.0.0,>=1.6.0 (from rasa[transformers]==3.6.15)\n",
            "  Downloading sanic_jwt-1.8.0-py3-none-any.whl (23 kB)\n",
            "Collecting sanic-routing<0.8.0,>=0.7.2 (from rasa[transformers]==3.6.15)\n",
            "  Downloading sanic_routing-0.7.2-py3-none-any.whl (23 kB)\n",
            "Collecting scikit-learn<1.2,>=0.22 (from rasa[transformers]==3.6.15)\n",
            "  Downloading scikit_learn-1.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.5/30.5 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from rasa[transformers]==3.6.15) (1.11.4)\n",
            "Collecting sentry-sdk<1.15.0,>=0.17.0 (from rasa[transformers]==3.6.15)\n",
            "  Downloading sentry_sdk-1.14.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.9/178.9 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from rasa[transformers]==3.6.15) (67.7.2)\n",
            "Collecting sklearn-crfsuite<0.4,>=0.3 (from rasa[transformers]==3.6.15)\n",
            "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
            "Collecting slack-sdk<4.0.0,>=3.19.2 (from rasa[transformers]==3.6.15)\n",
            "  Downloading slack_sdk-3.27.1-py2.py3-none-any.whl (285 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.7/285.7 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting structlog<24.0.0,>=23.1.0 (from rasa[transformers]==3.6.15)\n",
            "  Downloading structlog-23.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.0/66.0 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting structlog-sentry<3.0.0,>=2.0.2 (from rasa[transformers]==3.6.15)\n",
            "  Downloading structlog_sentry-2.1.0-py3-none-any.whl (11 kB)\n",
            "Collecting tarsafe<0.0.5,>=0.0.3 (from rasa[transformers]==3.6.15)\n",
            "  Downloading tarsafe-0.0.4-py3-none-any.whl (5.3 kB)\n",
            "Collecting tensorflow==2.12.0 (from rasa[transformers]==3.6.15)\n",
            "  Downloading tensorflow-2.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-io-gcs-filesystem==0.32 (from rasa[transformers]==3.6.15)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.32.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-text==2.12.0 (from rasa[transformers]==3.6.15)\n",
            "  Downloading tensorflow_text-2.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m100.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow_hub<0.14.0,>=0.13.0 (from rasa[transformers]==3.6.15)\n",
            "  Downloading tensorflow_hub-0.13.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.6/100.6 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting terminaltables<3.2.0,>=3.1.0 (from rasa[transformers]==3.6.15)\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.31 in /usr/local/lib/python3.10/dist-packages (from rasa[transformers]==3.6.15) (4.66.2)\n",
            "Collecting twilio<8.3,>=6.26 (from rasa[transformers]==3.6.15)\n",
            "  Downloading twilio-8.2.2-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions<5.0.0,>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from rasa[transformers]==3.6.15) (4.11.0)\n",
            "Collecting typing-utils<0.2.0,>=0.1.0 (from rasa[transformers]==3.6.15)\n",
            "  Downloading typing_utils-0.1.0-py3-none-any.whl (10 kB)\n",
            "Collecting ujson<6.0,>=1.35 (from rasa[transformers]==3.6.15)\n",
            "  Downloading ujson-5.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.2/53.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting webexteamssdk<1.7.0,>=1.1.1 (from rasa[transformers]==3.6.15)\n",
            "  Downloading webexteamssdk-1.6.1-py3-none-any.whl (113 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.5/113.5 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<11.0,>=10.0 (from rasa[transformers]==3.6.15)\n",
            "  Downloading websockets-10.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.38.1 in /usr/local/lib/python3.10/dist-packages (from rasa[transformers]==3.6.15) (0.43.0)\n",
            "Requirement already satisfied: sentencepiece[sentencepiece]<0.2.0,>=0.1.99 in /usr/local/lib/python3.10/dist-packages (from rasa[transformers]==3.6.15) (0.1.99)\n",
            "Collecting transformers<=4.26.0,>=4.13.0 (from rasa[transformers]==3.6.15)\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from dask==2022.10.2->rasa[transformers]==3.6.15) (8.1.7)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from dask==2022.10.2->rasa[transformers]==3.6.15) (2023.6.0)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.10/dist-packages (from dask==2022.10.2->rasa[transformers]==3.6.15) (1.4.1)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from dask==2022.10.2->rasa[transformers]==3.6.15) (0.12.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0->rasa[transformers]==3.6.15) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0->rasa[transformers]==3.6.15) (24.3.25)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.12.0->rasa[transformers]==3.6.15)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0->rasa[transformers]==3.6.15) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0->rasa[transformers]==3.6.15) (1.62.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0->rasa[transformers]==3.6.15) (3.9.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0->rasa[transformers]==3.6.15) (0.4.26)\n",
            "Collecting keras<2.13,>=2.12.0 (from tensorflow==2.12.0->rasa[transformers]==3.6.15)\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0->rasa[transformers]==3.6.15) (18.1.1)\n",
            "Collecting numpy<1.25.0,>=1.19.2 (from rasa[transformers]==3.6.15)\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0->rasa[transformers]==3.6.15) (3.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0->rasa[transformers]==3.6.15) (1.16.0)\n",
            "Collecting tensorboard<2.13,>=2.12 (from tensorflow==2.12.0->rasa[transformers]==3.6.15)\n",
            "  Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow==2.12.0->rasa[transformers]==3.6.15)\n",
            "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0->rasa[transformers]==3.6.15) (2.4.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0->rasa[transformers]==3.6.15) (1.14.1)\n",
            "Collecting aiormq~=6.4.0 (from aio-pika<8.2.4,>=6.7.1->rasa[transformers]==3.6.15)\n",
            "  Downloading aiormq-6.4.2-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: yarl in /usr/local/lib/python3.10/dist-packages (from aio-pika<8.2.4,>=6.7.1->rasa[transformers]==3.6.15) (1.9.4)\n",
            "Collecting Babel<2.10.0,>=2.9.1 (from aiogram<2.26->rasa[transformers]==3.6.15)\n",
            "  Downloading Babel-2.9.1-py2.py3-none-any.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m119.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting magic-filter>=1.0.9 (from aiogram<2.26->rasa[transformers]==3.6.15)\n",
            "  Downloading magic_filter-1.0.12-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=3.7.4.post0,<3.9,>=3.6->rasa[transformers]==3.6.15) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=3.7.4.post0,<3.9,>=3.6->rasa[transformers]==3.6.15) (6.0.5)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=3.7.4.post0,<3.9,>=3.6->rasa[transformers]==3.6.15) (4.0.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=3.7.4.post0,<3.9,>=3.6->rasa[transformers]==3.6.15) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=3.7.4.post0,<3.9,>=3.6->rasa[transformers]==3.6.15) (1.3.1)\n",
            "Requirement already satisfied: tzlocal!=3.*,>=2.0 in /usr/local/lib/python3.10/dist-packages (from apscheduler<3.10,>=3.6->rasa[transformers]==3.6.15) (5.2)\n",
            "Collecting botocore<1.35.0,>=1.34.92 (from boto3<2.0.0,>=1.26.136->rasa[transformers]==3.6.15)\n",
            "  Downloading botocore-1.34.92-py3-none-any.whl (12.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m106.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0.0,>=1.26.136->rasa[transformers]==3.6.15)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0.0,>=1.26.136->rasa[transformers]==3.6.15)\n",
            "  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from CacheControl<0.13.0,>=0.12.9->rasa[transformers]==3.6.15) (1.0.8)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs<16,>=10->rasa[transformers]==3.6.15)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=41.0.2->rasa[transformers]==3.6.15) (1.16.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3->rasa[transformers]==3.6.15) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3->rasa[transformers]==3.6.15) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3->rasa[transformers]==3.6.15) (4.9)\n",
            "Collecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 (from jsonschema<4.18,>=3.2->rasa[transformers]==3.6.15)\n",
            "  Downloading pyrsistent-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.6,>=3.1->rasa[transformers]==3.6.15) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.6,>=3.1->rasa[transformers]==3.6.15) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.6,>=3.1->rasa[transformers]==3.6.15) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.6,>=3.1->rasa[transformers]==3.6.15) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.6,>=3.1->rasa[transformers]==3.6.15) (3.1.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit<3.0.29,>=3.0->rasa[transformers]==3.6.15) (0.2.13)\n",
            "Collecting docopt>=0.6.2 (from pykwalify<1.9,>=1.7->rasa[transformers]==3.6.15)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting simple-websocket>=0.10.0 (from python-engineio!=5.0.0,<6,>=4->rasa[transformers]==3.6.15)\n",
            "  Downloading simple_websocket-1.0.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: bidict>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from python-socketio<6,>=4.4->rasa[transformers]==3.6.15) (0.23.1)\n",
            "Collecting fire (from randomname<0.2.0,>=0.1.5->rasa[transformers]==3.6.15)\n",
            "  Downloading fire-0.6.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.4/88.4 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.23->rasa[transformers]==3.6.15) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.23->rasa[transformers]==3.6.15) (2.0.7)\n",
            "Collecting ruamel.yaml.clib>=0.2.6 (from ruamel.yaml<0.17.22,>=0.16.5->rasa[transformers]==3.6.15)\n",
            "  Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (526 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.0.10 (from sanic<21.13,>=21.12->rasa[transformers]==3.6.15)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles>=0.6.0 (from sanic<21.13,>=21.12->rasa[transformers]==3.6.15)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=3.7.4.post0,<3.9,>=3.6->rasa[transformers]==3.6.15)\n",
            "  Downloading multidict-5.2.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.1/175.1 kB\u001b[0m \u001b[31m860.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvloop>=0.5.3 (from sanic<21.13,>=21.12->rasa[transformers]==3.6.15)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m111.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.2,>=0.22->rasa[transformers]==3.6.15) (3.4.0)\n",
            "\u001b[33mWARNING: sentencepiece 0.1.99 does not provide the extra 'sentencepiece'\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting python-crfsuite>=0.8.3 (from sklearn-crfsuite<0.4,>=0.3->rasa[transformers]==3.6.15)\n",
            "  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite<0.4,>=0.3->rasa[transformers]==3.6.15) (0.9.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<1.5.0,>=1.4.0->rasa[transformers]==3.6.15) (3.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers<=4.26.0,>=4.13.0->rasa[transformers]==3.6.15) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.26.0,>=4.13.0->rasa[transformers]==3.6.15) (0.20.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<=4.26.0,>=4.13.0->rasa[transformers]==3.6.15)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m106.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp-retry>=2.8.3 (from twilio<8.3,>=6.26->rasa[transformers]==3.6.15)\n",
            "  Downloading aiohttp_retry-2.8.3-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from webexteamssdk<1.7.0,>=1.1.1->rasa[transformers]==3.6.15) (0.18.3)\n",
            "Collecting requests-toolbelt (from webexteamssdk<1.7.0,>=1.1.1->rasa[transformers]==3.6.15)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pamqp==3.2.1 (from aiormq~=6.4.0->aio-pika<8.2.4,>=6.7.1->rasa[transformers]==3.6.15)\n",
            "  Downloading pamqp-3.2.1-py2.py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=41.0.2->rasa[transformers]==3.6.15) (2.22)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0->rasa[transformers]==3.6.15) (0.2.0)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=0.3.10->dask==2022.10.2->rasa[transformers]==3.6.15) (1.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3->rasa[transformers]==3.6.15) (0.6.0)\n",
            "Collecting wsproto (from simple-websocket>=0.10.0->python-engineio!=5.0.0,<6,>=4->rasa[transformers]==3.6.15)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow==2.12.0->rasa[transformers]==3.6.15)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0->rasa[transformers]==3.6.15) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0->rasa[transformers]==3.6.15) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0->rasa[transformers]==3.6.15) (3.0.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0->rasa[transformers]==3.6.15) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0->rasa[transformers]==3.6.15) (2.1.5)\n",
            "Collecting h11<1,>=0.9.0 (from wsproto->simple-websocket>=0.10.0->python-engineio!=5.0.0,<6,>=4->rasa[transformers]==3.6.15)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0->rasa[transformers]==3.6.15) (3.2.2)\n",
            "Building wheels for collected packages: mattermostwrapper, randomname, docopt, fire\n",
            "  Building wheel for mattermostwrapper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mattermostwrapper: filename=mattermostwrapper-2.2-py3-none-any.whl size=2448 sha256=80c1d685554b1bb0c26b0fd7ef42e14753c3b1583fb6898d4a8517b45a277a46\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/dc/02/e3239f0ea0a676085826846d32ef09b10915c0a33c817d2dbb\n",
            "  Building wheel for randomname (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for randomname: filename=randomname-0.1.5-py3-none-any.whl size=58808 sha256=9557d582f6a46c7266f5eb5480ff239f5167502aae8c57089647bfbaf1b154c7\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/df/c1/0bdf17c694217f49657ca36fd0239b9a243c34c27a70ff56ef\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=1ce6ebc85e064dfed9e114d92c87266f3b97bd36c316f16e416ee8274cbe8aae\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117029 sha256=4f116b078a5462533f9f90048c207f596b83537f9a755c8c14c9814ce588230f\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/6d/5d/5b73fa0f46d01a793713f8859201361e9e581ced8c75e5c6a3\n",
            "Successfully built mattermostwrapper randomname docopt fire\n",
            "Installing collected packages: tokenizers, sanic-routing, pytz, python-crfsuite, docopt, confluent-kafka, websockets, uvloop, ujson, typing-utils, terminaltables, tensorflow-io-gcs-filesystem, tensorflow-estimator, tarsafe, structlog, SQLAlchemy, slack-sdk, sklearn-crfsuite, sentry-sdk, sanic-jwt, ruamel.yaml.clib, regex, redis, pyrsistent, pydantic, psycopg2-binary, protobuf, prompt-toolkit, portalocker, pamqp, packaging, numpy, networkx, multidict, magic-filter, keras, joblib, jmespath, humanfriendly, httptools, h11, gast, fire, dnspython, colorhash, colorclass, Babel, attrs, apscheduler, aiofiles, wsproto, tensorflow_hub, structlog-sentry, sanic, ruamel.yaml, rocketchat_API, requests-toolbelt, randomname, questionary, pymongo, mattermostwrapper, matplotlib, jsonschema, fbmessenger, dask, coloredlogs, CacheControl, botocore, webexteamssdk, transformers, simple-websocket, scikit-learn, sanic-cors, s3transfer, pykwalify, google-auth-oauthlib, aiormq, aiohttp, tensorboard, rasa-sdk, python-engineio, boto3, aiohttp-retry, aiogram, aio-pika, twilio, tensorflow, python-socketio, tensorflow-text, rasa\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2023.4\n",
            "    Uninstalling pytz-2023.4:\n",
            "      Successfully uninstalled pytz-2023.4\n",
            "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
            "    Found existing installation: tensorflow-io-gcs-filesystem 0.36.0\n",
            "    Uninstalling tensorflow-io-gcs-filesystem-0.36.0:\n",
            "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.36.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.15.0\n",
            "    Uninstalling tensorflow-estimator-2.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.15.0\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.29\n",
            "    Uninstalling SQLAlchemy-2.0.29:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.29\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2023.12.25\n",
            "    Uninstalling regex-2023.12.25:\n",
            "      Successfully uninstalled regex-2023.12.25\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.7.0\n",
            "    Uninstalling pydantic-2.7.0:\n",
            "      Successfully uninstalled pydantic-2.7.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: prompt-toolkit\n",
            "    Found existing installation: prompt-toolkit 3.0.43\n",
            "    Uninstalling prompt-toolkit-3.0.43:\n",
            "      Successfully uninstalled prompt-toolkit-3.0.43\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.3\n",
            "    Uninstalling networkx-3.3:\n",
            "      Successfully uninstalled networkx-3.3\n",
            "  Attempting uninstall: multidict\n",
            "    Found existing installation: multidict 6.0.5\n",
            "    Uninstalling multidict-6.0.5:\n",
            "      Successfully uninstalled multidict-6.0.5\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.4.0\n",
            "    Uninstalling joblib-1.4.0:\n",
            "      Successfully uninstalled joblib-1.4.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.4\n",
            "    Uninstalling gast-0.5.4:\n",
            "      Successfully uninstalled gast-0.5.4\n",
            "  Attempting uninstall: Babel\n",
            "    Found existing installation: Babel 2.14.0\n",
            "    Uninstalling Babel-2.14.0:\n",
            "      Successfully uninstalled Babel-2.14.0\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 23.2.0\n",
            "    Uninstalling attrs-23.2.0:\n",
            "      Successfully uninstalled attrs-23.2.0\n",
            "  Attempting uninstall: tensorflow_hub\n",
            "    Found existing installation: tensorflow-hub 0.16.1\n",
            "    Uninstalling tensorflow-hub-0.16.1:\n",
            "      Successfully uninstalled tensorflow-hub-0.16.1\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.19.2\n",
            "    Uninstalling jsonschema-4.19.2:\n",
            "      Successfully uninstalled jsonschema-4.19.2\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2023.8.1\n",
            "    Uninstalling dask-2023.8.1:\n",
            "      Successfully uninstalled dask-2023.8.1\n",
            "  Attempting uninstall: CacheControl\n",
            "    Found existing installation: CacheControl 0.14.0\n",
            "    Uninstalling CacheControl-0.14.0:\n",
            "      Successfully uninstalled CacheControl-0.14.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.40.0\n",
            "    Uninstalling transformers-4.40.0:\n",
            "      Successfully uninstalled transformers-4.40.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.0\n",
            "    Uninstalling google-auth-oauthlib-1.2.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.0\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.9.5\n",
            "    Uninstalling aiohttp-3.9.5:\n",
            "      Successfully uninstalled aiohttp-3.9.5\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-nccl-cu12==2.19.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "bigframes 1.2.0 requires matplotlib>=3.7.1, but you have matplotlib 3.5.3 which is incompatible.\n",
            "bigframes 1.2.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.1.3 which is incompatible.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "distributed 2023.8.1 requires dask==2023.8.1, but you have dask 2022.10.2 which is incompatible.\n",
            "ipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.4.52 which is incompatible.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n",
            "plotnine 0.12.4 requires matplotlib>=3.6.0, but you have matplotlib 3.5.3 which is incompatible.\n",
            "referencing 0.34.0 requires attrs>=22.2.0, but you have attrs 22.1.0 which is incompatible.\n",
            "statsmodels 0.14.2 requires packaging>=21.3, but you have packaging 20.9 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.23.3 which is incompatible.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.12.0 which is incompatible.\n",
            "xarray 2023.7.0 requires packaging>=21.3, but you have packaging 20.9 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Babel-2.9.1 CacheControl-0.12.14 SQLAlchemy-1.4.52 aio-pika-8.2.3 aiofiles-23.2.1 aiogram-2.25.2 aiohttp-3.8.6 aiohttp-retry-2.8.3 aiormq-6.4.2 apscheduler-3.9.1.post1 attrs-22.1.0 boto3-1.34.92 botocore-1.34.92 colorclass-2.2.2 coloredlogs-15.0.1 colorhash-1.2.1 confluent-kafka-2.3.0 dask-2022.10.2 dnspython-2.3.0 docopt-0.6.2 fbmessenger-6.0.0 fire-0.6.0 gast-0.4.0 google-auth-oauthlib-1.0.0 h11-0.14.0 httptools-0.6.1 humanfriendly-10.0 jmespath-1.0.1 joblib-1.2.0 jsonschema-4.17.3 keras-2.12.0 magic-filter-1.0.12 matplotlib-3.5.3 mattermostwrapper-2.2 multidict-5.2.0 networkx-2.6.3 numpy-1.23.5 packaging-20.9 pamqp-3.2.1 portalocker-2.8.2 prompt-toolkit-3.0.28 protobuf-4.23.3 psycopg2-binary-2.9.9 pydantic-1.10.9 pykwalify-1.8.0 pymongo-4.3.3 pyrsistent-0.20.0 python-crfsuite-0.9.10 python-engineio-4.9.0 python-socketio-5.11.2 pytz-2022.7.1 questionary-1.10.0 randomname-0.1.5 rasa-3.6.15 rasa-sdk-3.6.2 redis-4.6.0 regex-2022.10.31 requests-toolbelt-1.0.0 rocketchat_API-1.30.0 ruamel.yaml-0.17.21 ruamel.yaml.clib-0.2.8 s3transfer-0.10.1 sanic-21.12.2 sanic-cors-2.0.1 sanic-jwt-1.8.0 sanic-routing-0.7.2 scikit-learn-1.1.3 sentry-sdk-1.14.0 simple-websocket-1.0.0 sklearn-crfsuite-0.3.6 slack-sdk-3.27.1 structlog-23.3.0 structlog-sentry-2.1.0 tarsafe-0.0.4 tensorboard-2.12.3 tensorflow-2.12.0 tensorflow-estimator-2.12.0 tensorflow-io-gcs-filesystem-0.32.0 tensorflow-text-2.12.0 tensorflow_hub-0.13.0 terminaltables-3.1.10 tokenizers-0.13.3 transformers-4.26.0 twilio-8.2.2 typing-utils-0.1.0 ujson-5.9.0 uvloop-0.19.0 webexteamssdk-1.6.1 websockets-10.4 wsproto-1.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "packaging",
                  "prompt_toolkit"
                ]
              },
              "id": "b378e69868c942b2ace41a659d4c09d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nest-asyncio==1.5.6\n",
            "  Downloading nest_asyncio-1.5.6-py3-none-any.whl (5.2 kB)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (5.5.6)\n",
            "Collecting ipykernel\n",
            "  Downloading ipykernel-6.29.4-py3-none-any.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.1/117.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting comm>=0.1.1 (from ipykernel)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (1.6.6)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (6.1.12)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (5.7.2)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ipykernel) (1.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ipykernel) (20.9)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ipykernel) (5.9.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prepare the training data\n"
      ],
      "metadata": {
        "id": "C7nGBkEjVEiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = {\n",
        "    \"Great-hi\" : [\n",
        "        \"Bonjour, comment ça va aujourd'hui?\",\n",
        "        \"Hi, how's everything going on your end?\",\n",
        "        \"Salut\",\n",
        "        \"Hey there!\",\n",
        "        \"Hey, what's going on?\",\n",
        "        \"Hey, how's everything been going with you?\",\n",
        "        \"Salut, content de te voir\",\n",
        "        \"Hello, how's it been going?\",\n",
        "        \"Hi, how are things on your end?\",\n",
        "        \"Hi, how's your day coming along?\",\n",
        "        \"Hey, how's your day been so far?\",\n",
        "        \"Salut, ça va?\",\n",
        "        \"Hi, how are you doing?\",\n",
        "        \"Bonjour, comment ça va depuis la dernière fois?\",\n",
        "        \"Hey, how's your day going?\",\n",
        "        \"Salut, comment ça va?\",\n",
        "        \"Hi, how's your day been?\",\n",
        "        \"Hey, what's happening?\",\n",
        "        \"Coucou, comment vas-tu aujourd'hui?\",\n",
        "        \"Hey, how's everything?\",\n",
        "        \"Hello, how can I help you?\",\n",
        "        \"Hi, how are you today?\",\n",
        "        \"Salut, comment ça se passe?\",\n",
        "        \"Coucou, quoi de beau?\",\n",
        "        \"Hey, what's new?\",\n",
        "        \"Hi, how are you getting by?\",\n",
        "        \"Bonjour, ça va?\",\n",
        "        \"Hi, how's your day turning out?\",\n",
        "        \"Salut, content de te retrouver\",\n",
        "        \"Hiya!\",\n",
        "        \"Hey, long time no see!\",\n",
        "        \"Hello, how are things with you?\",\n",
        "        \"Salut, ça fait plaisir de te voir\",\n",
        "        \"Hi, how are things?\",\n",
        "        \"What's up?\",\n",
        "        \"Hello, how's your week been?\",\n",
        "        \"Hi, how are you coping?\",\n",
        "        \"Hey, what's happening with your day?\",\n",
        "        \"Hi, how are you making out?\",\n",
        "        \"Salut, comment s'est passé ta journée?\",\n",
        "        \"Hey, how's your day shaping up?\",\n",
        "        \"Hi, how are you holding up?\",\n",
        "        \"Hey, how's life treating you?\",\n",
        "        \"Hi, how are you coming along?\",\n",
        "        \"Bonjour, comment ça va?\",\n",
        "        \"Hello, how's your day so far?\",\n",
        "        \"Hi, how are you managing?\",\n",
        "        \"Hey, what's the buzz?\",\n",
        "        \"Hi, how are you holding up today?\",\n",
        "        \"Bonjour, tout va bien?\",\n",
        "        \"Hey, how's everything been shaping up?\",\n",
        "        \"Hi, how are you doing these days?\",\n",
        "        \"Hey, what's happening with you?\",\n",
        "        \"Hi, how are you feeling?\",\n",
        "        \"Hey, how's your day unfolding?\",\n",
        "        \"Hi, how's your week been going?\",\n",
        "        \"Bonjour, tu vas bien?\",\n",
        "        \"Hello, how's everything with you?\",\n",
        "        \"Hi, what's happening?\",\n",
        "        \"Hey, how's your day panning out?\",\n",
        "        \"Hi, how's everything turning out?\",\n",
        "        \"Bonjour, salut?\",\n",
        "        \"Hi, nice to meet you!\",\n",
        "        \"Hello, how's everything treating you?\",\n",
        "        \"Hi, how are you holding up lately?\",\n",
        "        \"Hey, how's your day been treating you so far?\",\n",
        "        \"Hi, how are you doing lately?\",\n",
        "        \"Bonjour, comment ça va?\",\n",
        "        \"Hey, how's your day progressing?\",\n",
        "        \"Hi, how are you getting along?\",\n",
        "        \"Hello, how's it going lately?\",\n",
        "        \"Hi, how's everything holding up?\",\n",
        "        \"Hey, what's the latest?\",\n",
        "        \"Salut, comment va ta journée?\",\n",
        "        \"Hi, how's your day unfolding so far?\",\n",
        "        \"Hello, how's your day been going so far?\",\n",
        "        \"Hi, how's your week turning out so far?\",\n",
        "        \"Hey, how are you feeling today?\",\n",
        "        \"Salut, ça fait longtemps!\",\n",
        "        \"Hi, how's your evening?\",\n",
        "        \"Bonjour, comment ça va?\",\n",
        "        \"Hey, what's going on with you?\",\n",
        "        \"Hi, how are you keeping?\",\n",
        "        \"Hello, how's everything been working out?\",\n",
        "        \"Hi, what's the news?\",\n",
        "        \"Salut, quoi de neuf?\",\n",
        "        \"Hi, how's it hanging?\",\n",
        "        \"Bonjour, tu as passé une bonne journée?\",\n",
        "        \"Hey, how are things going for you?\",\n",
        "        \"Hi, how's your day been treating you lately?\",\n",
        "        \"Salut, comment ça va?\",\n",
        "        \"Hey, how are you managing lately?\",\n",
        "        \"Hi, how's everything with you?\",\n",
        "        \"Hello, how's it hanging?\",\n",
        "        \"Hi, how's your morning been?\",\n",
        "        \"Hey, how are you doing?\",\n",
        "        \"Bonjour, comment ça va aujourd'hui?\",\n",
        "        \"Hey, how are you coming along lately?\",\n",
        "        \"Hi, how's your day shaping up so far?\",\n",
        "        \"Salut, ça va bien?\",\n",
        "        \"Hi, how's everything going for you?\",\n",
        "        \"Hello, how's everything been going on your side?\",\n",
        "        \"Hi, how's it going on your end?\",\n",
        "        \"Hey, how's your day been going so far?\",\n",
        "        \"Hi, what's up?\",\n",
        "        \"Bonjour, salut!\",\n",
        "        \"Hey, what's been going on?\",\n",
        "        \"Hi, how are you today?\",\n",
        "        \"Hello, how's your day unfolding?\",\n",
        "        \"Hi, how's your day been?\",\n",
        "        \"Hey, how's everything been going for you lately?\",\n",
        "        \"Hi, how are you holding up?\",\n",
        "        \"Salut, comment ça va?\",\n",
        "        \"Hi, how are you doing?\",\n",
        "        \"Hey, how's your day turning out?\",\n",
        "        \"Salut, comment ça va?\",\n",
        "        \"Hi, how are things?\",\n",
        "        \"Bonjour, ça va?\",\n",
        "        \"Hello, how's it been going?\",\n",
        "        \"Hi, how are you managing?\",\n",
        "        \"Hey, what's happening with your day?\",\n",
        "        \"Hi, how are you making out?\",\n",
        "        \"Salut, comment s'est passé ta journée?\",\n",
        "        \"Hey, how's your day shaping up?\",\n",
        "        \"Hi, how are you holding up?\",\n",
        "        \"Hey, how's life treating you?\",\n",
        "        \"Hi, how are you coming along?\",\n",
        "        \"Bonjour, comment ça va?\",\n",
        "        \"Hello, how's your day so far?\",\n",
        "        \"Hi, how are you managing?\",\n",
        "        \"Hey, what's the buzz?\",\n",
        "        \"Hi, how are you holding up today?\",\n",
        "        \"Salut, tout va bien?\",\n",
        "        \"Hey, how's everything been shaping up?\",\n",
        "        \"Hi, how are you doing these days?\",\n",
        "        \"Hey, what's happening with you?\",\n",
        "        \"Hi, how are you feeling?\",\n",
        "        \"Hey, how's your day unfolding?\",\n",
        "        \"Hi, how's your week been going?\",\n",
        "        \"Bonjour, tu vas bien?\",\n",
        "        \"Hello, how's everything with you?\",\n",
        "        \"Hi, what's happening?\",\n",
        "        \"Hey, how's your day panning out?\",\n",
        "        \"Hi, how's everything turning out?\",\n",
        "        \"Salut, comment va ta journée?\",\n",
        "        \"Hi, nice to meet you!\",\n",
        "        \"Hello, how's everything treating you?\",\n",
        "        \"Hi, how are you holding up lately?\",\n",
        "        \"Hey, how's your day been treating you so far?\",\n",
        "        \"Hi, how are you doing lately?\",\n",
        "        \"Bonjour, comment ça va?\",\n",
        "        \"Hey, how's your day progressing?\",\n",
        "        \"Hi, how are you getting along?\", ],\n",
        "\n",
        "     \"who_are_you\" : [\n",
        "        \"Who am I speaking with?\",\n",
        "        \"Qui êtes-vous exactement?\",\n",
        "        \"What exactly are you?\",\n",
        "        \"Qui exactement êtes-vous?\",\n",
        "        \"Quel est votre objectif?\",\n",
        "        \"Who are you?\",\n",
        "        \"Comment pouvez-vous m'aider?\",\n",
        "        \"What are you?\",\n",
        "        \"Quels sont vos capacités?\",\n",
        "        \"How can you assist me?\",\n",
        "        \"Que faites-vous?\",\n",
        "        \"Why do I need your help?\",\n",
        "        \"Quel est votre fonction?\",\n",
        "        \"What is your role?\",\n",
        "        \"What are you here for?\",\n",
        "        \"Pouvez-vous me parler de vous?\",\n",
        "        \"What do you offer?\",\n",
        "        \"Quelles sont vos capacités?\",\n",
        "        \"What is your purpose?\",\n",
        "        \"Comment pouvez-vous m'aider?\",\n",
        "        \"Why should I use your services?\",\n",
        "        \"What is votre objectif?\",\n",
        "        \"What do you specialize in?\",\n",
        "        \"What are your abilities?\",\n",
        "        \"Why are you here?\",\n",
        "        \"Qu'est-ce que vous fournissez?\",\n",
        "        \"Who is behind you?\",\n",
        "        \"How do you help?\",\n",
        "        \"What services do you provide?\",\n",
        "        \"What assistance do you offer?\",\n",
        "        \"What is your main function?\",\n",
        "        \"Que faites-vous exactement?\",\n",
        "        \"Who created you?\",\n",
        "        \"What are your features?\",\n",
        "        \"How do you work?\",\n",
        "        \"What is your main purpose?\",\n",
        "        \"Qui est votre créateur?\",\n",
        "        \"What are your strengths?\",\n",
        "        \"What do you do exactly?\",\n",
        "        \"How do you support users?\",\n",
        "        \"What are your skills?\",\n",
        "        \"What is your primary function?\",\n",
        "        \"Qui vous a créé?\",\n",
        "        \"What are your main features?\",\n",
        "        \"What are your main abilities?\",\n",
        "        \"What do you do for users?\",\n",
        "        \"How do you function?\",\n",
        "        \"What do you excel at?\",\n",
        "        \"What are your main capabilities?\",\n",
        "        \"Who developed you?\",\n",
        "        \"What services do you provide?\",\n",
        "        \"What kind of help can you offer?\",\n",
        "        \"What are you capable of?\",\n",
        "        \"What do you provide assistance with?\",\n",
        "        \"Who programmed you?\",\n",
        "        \"Quels sont vos principales tâches?\",\n",
        "        \"What is your purpose here?\",\n",
        "        \"Who built you?\",\n",
        "        \"What can you help me with?\",\n",
        "        \"What tasks can you perform?\",\n",
        "        \"Who is your developer?\",\n",
        "        \"What benefits do you offer?\",\n",
        "        \"What can you do to help me?\",\n",
        "        \"Qui est votre créateur?\",\n",
        "        \"What are your main functions?\",\n",
        "        \"What do you offer users?\",\n",
        "        \"Who is your designer?\",\n",
        "        \"What can you assist with?\",\n",
        "        \"Who designed you?\",\n",
        "        \"What are your primary functions?\",\n",
        "        \"What is your creator?\",\n",
        "        \"What kind of support do you provide?\",\n",
        "        \"Who is responsible for you?\",\n",
        "        \"What are your main purposes?\",\n",
        "        \"What do you bring to the table?\",\n",
        "        \"Who is your inventor?\",\n",
        "        \"What is your purpose of existence?\",\n",
        "        \"Who came up with you?\",\n",
        "        \"What services do you render?\",\n",
        "        \"What are your primary features?\",\n",
        "        \"Who put you together?\",\n",
        "        \"What exactly do you do?\",\n",
        "        \"Who is your manufacturer?\",\n",
        "        \"What are your main tasks?\",\n",
        "        \"Who is your manufacturer?\",\n",
        "        \"What exactly are your capabilities?\",\n",
        "        \"Who developed you?\",\n",
        "        \"What exactly do you specialize in?\",\n",
        "        \"Qui vous a créé?\",\n",
        "        \"Who created you?\",\n",
        "        \"What is your exact role?\",\n",
        "        \"What kind of help do you provide?\",\n",
        "        \"Who is behind your creation?\",\n",
        "        \"What exactly are your abilities?\",\n",
        "        \"Who is behind your design?\",\n",
        "        \"What exactly is your purpose?\",\n",
        "        \"What can you do\"\n",
        "    ] ,\n",
        "\n",
        "     \"great-good_bye\" : [\n",
        "        \"Au revoir!\",\n",
        "        \"Goodbye, take care!\",\n",
        "        \"See you later!\",\n",
        "        \"Adieu!\",\n",
        "        \"À bientôt!\",\n",
        "        \"Goodbye!\",\n",
        "        \"See you soon!\",\n",
        "        \"À la prochaine!\",\n",
        "        \"Bye!\",\n",
        "        \"See you!\",\n",
        "        \"À plus tard!\",\n",
        "        \"Farewell!\",\n",
        "        \"See you next time!\",\n",
        "        \"Bye bye!\",\n",
        "        \"Ciao!\",\n",
        "        \"À tout à l'heure!\",\n",
        "        \"Goodbye, have a great day!\",\n",
        "        \"Bon voyage!\",\n",
        "        \"Hasta la vista!\",\n",
        "        \"Take care!\",\n",
        "        \"Bonne journée!\",\n",
        "        \"Adios!\",\n",
        "        \"Have a good one!\",\n",
        "        \"Bonsoir!\",\n",
        "        \"So long!\",\n",
        "        \"À demain!\",\n",
        "        \"Goodbye, it was nice talking to you!\",\n",
        "        \"À ce soir!\",\n",
        "        \"Goodnight!\",\n",
        "        \"Take it easy!\",\n",
        "        \"Salut, à la prochaine!\",\n",
        "        \"Aurevoir!\",\n",
        "        \"Hasta luego!\",\n",
        "        \"À la revoyure!\",\n",
        "        \"Goodbye, see you around!\",\n",
        "        \"À plus!\",\n",
        "        \"Catch you later!\",\n",
        "        \"Bonne nuit!\",\n",
        "        \"Bonsoir, à demain!\",\n",
        "        \"Goodbye, until next time!\",\n",
        "        \"Bonne soirée!\",\n",
        "        \"Goodbye, have a nice evening!\",\n",
        "        \"À tout!\",\n",
        "        \"À la semaine prochaine!\",\n",
        "        \"Take care, goodbye!\",\n",
        "        \"Bon weekend!\",\n",
        "        \"So long, farewell!\",\n",
        "        \"À plus tard, mon ami!\",\n",
        "        \"Until we meet again!\",\n",
        "        \"À la prochaine fois!\",\n",
        "        \"Goodbye, see you tomorrow!\",\n",
        "        \"Bonne journée, au revoir!\",\n",
        "        \"À plus tard, à bientôt!\",\n",
        "        \"Goodbye, have a great weekend!\",\n",
        "        \"À bientôt, salut!\",\n",
        "        \"Adieu, mon ami!\",\n",
        "        \"À très bientôt!\",\n",
        "        \"À la prochaine fois, bye!\",\n",
        "        \"Goodbye, see you next week!\",\n",
        "        \"Bonne journée, à plus tard!\",\n",
        "        \"À la prochaine fois, salut!\",\n",
        "        \"Take care, see you later!\",\n",
        "        \"Bonne journée, à bientôt!\",\n",
        "        \"Goodbye, until we meet again!\",\n",
        "        \"À plus, à bientôt!\",\n",
        "        \"À demain, bonne nuit!\",\n",
        "        \"Goodbye, until tomorrow!\",\n",
        "        \"À plus tard, à demain!\",\n",
        "        \"Bonne soirée, au revoir!\",\n",
        "        \"À bientôt, à la prochaine!\",\n",
        "        \"Bonne soirée, à demain!\",\n",
        "        \"Goodbye, have a good night!\",\n",
        "        \"À bientôt, bonne journée!\",\n",
        "        \"À demain, à plus!\",\n",
        "        \"Goodbye, see you soon!\",\n",
        "        \"À très vite!\",\n",
        "        \"À bientôt, à la revoyure!\",\n",
        "        \"Bonne nuit, à demain!\",\n",
        "        \"À plus, bonne journée!\",\n",
        "        \"Goodbye, until later!\",\n",
        "        \"À demain, bonne journée!\",\n",
        "        \"À plus tard, salut!\",\n",
        "        \"Goodbye, until next week!\",\n",
        "        \"À très bientôt, mon ami!\",\n",
        "        \"À la semaine prochaine, au revoir!\",\n",
        "        \"À la revoyure, bonsoir!\",\n",
        "        \"À la prochaine fois, bonne soirée!\",\n",
        "        \"À bientôt, bonne soirée!\",\n",
        "        \"Goodbye, see you next time!\",\n",
        "        \"À bientôt, à la prochaine fois!\",\n",
        "        \"Bonne soirée, à plus tard!\",\n",
        "        \"À très vite, salut!\",\n",
        "        \"À bientôt, bonne nuit!\",\n",
        "        \"Goodbye, see you later!\",\n",
        "        \"À la revoyure, à demain!\",\n",
        "        \"À bientôt, à demain!\",\n",
        "        \"Goodbye, until tomorrow!\",\n",
        "        \"À plus tard, bonsoir!\",\n",
        "        \"À plus tard, bonne soirée!\",\n",
        "        \"À bientôt, bonne soirée!\",\n",
        "        \"Goodbye, see you tomorrow!\",\n",
        "        \"À très bientôt, bonne nuit!\",\n",
        "        \"À la prochaine, à plus!\",\n",
        "        \"Goodbye, until next time!\",\n",
        "        \"À bientôt, à la semaine prochaine!\",\n",
        "        \"À plus tard, à très vite!\",\n",
        "        \"À plus, à la prochaine fois!\",\n",
        "        \"Goodbye, have a nice day!\",\n",
        "        \"À plus tard, à la revoyure!\",\n",
        "        \"À la prochaine, bonne soirée!\",\n",
        "        \"Goodbye, see you next week!\",\n",
        "        \"À très bientôt, à demain!\",\n",
        "        \"À bientôt, à la semaine prochaine!\",\n",
        "        \"À la revoyure, à très bientôt!\",\n",
        "        \"Goodbye, see you later!\",\n",
        "        \"À plus tard, à la semaine prochaine!\",\n",
        "        \"À très vite, bonne journée!\",\n",
        "        \"À plus tard, bonne journée!\",\n",
        "        \"Goodbye, have a good evening!\",\n",
        "        \"À bientôt, à plus tard!\",\n",
        "        \"À plus tard, bonne soirée!\",\n",
        "        \"À la revoyure, à bientôt!\",\n",
        "        \"Goodbye, until later!\",\n",
        "        \"À très bientôt, à la revoyure!\",\n",
        "        \"À la prochaine fois, à demain!\",\n",
        "        \"À plus, bonne nuit!\",\n",
        "        \"Goodbye, see you soon!\",\n",
        "        \"À bientôt, bonne journée!\",\n",
        "        \"À la prochaine fois, bonne nuit!\",\n",
        "        \"À la revoyure, à la semaine prochaine!\",\n",
        "        \"Goodbye, see you next time!\",\n",
        "        \"À très bientôt, à plus tard!\",\n",
        "        \"À bientôt, à très bientôt!\",\n",
        "        \"À plus tard, à bientôt!\",\n",
        "        \"À plus, à demain!\",\n",
        "        \"Goodbye, until tomorrow!\",\n",
        "        \"À très vite, bonne soirée!\",\n",
        "        \"À la prochaine fois, à plus tard!\",\n",
        "        \"À bientôt, bonne soirée!\",\n",
        "        \"Goodbye, have a great day!\",\n",
        "        \"À bientôt, bonne soirée!\",\n",
        "        \"À la prochaine fois, à la semaine prochaine!\",\n",
        "        \"Goodbye, see you next week!\",\n",
        "        \"À plus tard, bonne journée!\",\n",
        "        \"À bientôt, bonne nuit!\",\n",
        "        \"À très bientôt, bonne soirée!\",\n",
        "        \"Goodbye, see you tomorrow!\",\n",
        "        \"À la revoyure, à la semaine prochaine!\",\n",
        "        \"À bientôt, à très bientôt!\",\n",
        "        \"À plus tard, à demain!\",\n",
        "        \"À la prochaine fois, à bientôt!\",\n",
        "        \"Goodbye, until later!\",\n",
        "        \"À très bientôt, à demain!\",\n",
        "        \"À plus tard, bonne soirée!\",\n",
        "        \"À la revoyure, à demain!\",\n",
        "        \"Goodbye, see you later!\",\n",
        "        \"À plus, bonne journée!\",\n",
        "        \"À la prochaine fois, bonne journée!\",\n",
        "        \"À bientôt, à la rev\",],\n",
        "\n",
        "    \"matches-team_next_match\": [\n",
        "        \"When will be the matches of [Arsenal](team_name)\",\n",
        "        \"Quand auront lieu les matchs de [Aston Villa](team_name)\",\n",
        "        \"Next matches of [Brentford](team_name)\",\n",
        "        \"Prochains matchs de [Brighton and Hove Albion](team_name)\",\n",
        "        \"Upcoming matches for [Bournemouth](team_name)\",\n",
        "        \"Matchs à venir pour [Burnley](team_name)\",\n",
        "        \"Any matches scheduled for [Chelsea](team_name)\",\n",
        "        \"Des matchs prévus pour [Crystal Palace](team_name)\",\n",
        "        \"When will be the matches of [Everton](team_name)\",\n",
        "        \"Quand auront lieu les matchs de [Fulham](team_name)\",\n",
        "        \"Next matches of [Liverpool](team_name)\",\n",
        "        \"Prochains matchs de [Luton Town](team_name)\",\n",
        "        \"Upcoming matches for [Manchester City](team_name)\",\n",
        "        \"Matchs à venir pour [Manchester United](team_name)\",\n",
        "        \"Any matches scheduled for [Newcastle United](team_name)\",\n",
        "        \"Des matchs prévus pour [Nottingham Forest](team_name)\",\n",
        "        \"When will be the matches of [Sheffield United](team_name)\",\n",
        "        \"Quand auront lieu les matchs de [Tottenham Hotspur](team_name)\",\n",
        "        \"Next matches of [West Ham United](team_name)\",\n",
        "        \"Prochains matchs de [Wolverhampton Wanderers](team_name)\",\n",
        "        \"Upcoming matches for [Arsenal](team_name)\",\n",
        "        \"Matchs à venir pour [Aston Villa](team_name)\",\n",
        "        \"Any matches scheduled for [Brentford](team_name)\",\n",
        "        \"Des matchs prévus pour [Brighton and Hove Albion](team_name)\",\n",
        "        \"When will be the matches of [Bournemouth](team_name)\",\n",
        "        \"Quand auront lieu les matchs de [Burnley](team_name)\",\n",
        "        \"Next matches of [Chelsea](team_name)\",\n",
        "        \"Prochains matchs de [Crystal Palace](team_name)\",\n",
        "        \"Upcoming matches for [Everton](team_name)\",\n",
        "        \"Matchs à venir pour [Fulham](team_name)\",\n",
        "        \"Any matches scheduled for [Liverpool](team_name)\",\n",
        "        \"Des matchs prévus pour [Luton Town](team_name)\",\n",
        "        \"When will be the matches of [Manchester City](team_name)\",\n",
        "        \"Quand auront lieu les matchs de [Manchester United](team_name)\",\n",
        "        \"Next matches of [Newcastle United](team_name)\",\n",
        "        \"Prochains matchs de [Nottingham Forest](team_name)\",\n",
        "        \"Upcoming matches for [Sheffield United](team_name)\",\n",
        "        \"Matchs à venir pour [Tottenham Hotspur](team_name)\",\n",
        "        \"Any matches scheduled for [West Ham United](team_name)\",\n",
        "        \"Des matchs prévus pour [Wolverhampton Wanderers](team_name)\",\n",
        "        \"When will be the matches of [Arsenal](team_name)\",\n",
        "        \"Quand auront lieu les matchs de [Aston Villa](team_name)\",\n",
        "        \"Next matches of [Brentford](team_name)\",\n",
        "        \"Prochains matchs de [Brighton and Hove Albion](team_name)\",\n",
        "        \"Upcoming matches for [Bournemouth](team_name)\",\n",
        "        \"Matchs à venir pour [Burnley](team_name)\",\n",
        "        \"Any matches scheduled for [Chelsea](team_name)\",\n",
        "        \"Des matchs prévus pour [Crystal Palace](team_name)\",\n",
        "        \"When will be the matches of [Everton](team_name)\",\n",
        "        \"Quand auront lieu les matchs de [Fulham](team_name)\",\n",
        "        \"Next matches of [Liverpool](team_name)\",\n",
        "        \"Prochains matchs de [Luton Town](team_name)\",\n",
        "        \"Upcoming matches for [Manchester City](team_name)\",\n",
        "        \"Matchs à venir pour [Manchester United](team_name)\",\n",
        "        \"Any matches scheduled for [Newcastle United](team_name)\",\n",
        "        \"Des matchs prévus pour [Nottingham Forest](team_name)\",\n",
        "        \"When will be the matches of [Sheffield United](team_name)\",\n",
        "        \"Quand auront lieu les matchs de [Tottenham Hotspur](team_name)\",\n",
        "        \"Next matches of [West Ham United](team_name)\",\n",
        "        \"Prochains matchs de [Wolverhampton Wanderers](team_name)\"\n",
        "    ],\n",
        "\n",
        "    \"matches-match_time\": [\n",
        "        \"When will be the match of [Arsenal](team_name) against [Manchester United](team_name)\",\n",
        "        \"Quand aura lieu le match d'[Arsenal](team_name) contre [Manchester United](team_name)\",\n",
        "        \"[Crystal Palace](team_name) vs [Liverpool](team_name) match time\",\n",
        "        \"[Crystal Palace](team_name) contre [Liverpool](team_name) heure du match\",\n",
        "        \"[Chelsea](team_name) vs [Tottenham Hotspur](team_name) match time\",\n",
        "        \"[Chelsea](team_name) contre [Tottenham Hotspur](team_name) heure du match\",\n",
        "        \"[Leeds United](team_name) vs [Manchester City](team_name) match time\",\n",
        "        \"[Leeds United](team_name) contre [Manchester City](team_name) heure du match\",\n",
        "        \"Tell me when [Everton](team_name) will play with [Aston Villa](team_name)\",\n",
        "        \"Dis-moi quand [Everton](team_name) jouera avec [Aston Villa](team_name)\",\n",
        "        \"Will [West Ham United](team_name) play against [Leicester City](team_name)\",\n",
        "        \"Est-ce que [West Ham United](team_name) jouera contre [Leicester City](team_name)\",\n",
        "        \"[Newcastle United](team_name) vs [Southampton](team_name) match time\",\n",
        "        \"[Newcastle United](team_name) contre [Southampton](team_name) heure du match\",\n",
        "        \"[Wolverhampton Wanderers](team_name) vs [Brighton and Hove Albion](team_name) match time\",\n",
        "        \"[Wolverhampton Wanderers](team_name) contre [Brighton and Hove Albion](team_name) heure du match\",\n",
        "        \"What's the match time for [Fulham](team_name) vs [Burnley](team_name)\",\n",
        "        \"Quelle est l'heure du match pour [Fulham](team_name) contre [Burnley](team_name)\",\n",
        "        \"Any matches scheduled for [Norwich City](team_name) and [Brentford](team_name)\",\n",
        "        \"Des matchs prévus pour [Norwich City](team_name) et [Brentford](team_name)\",\n",
        "        \"When will be the match of [Chelsea](team_name) against [Liverpool](team_name)\",\n",
        "        \"Quand aura lieu le match de [Chelsea](team_name) contre [Liverpool](team_name)\",\n",
        "        \"[Manchester United](team_name) vs [Manchester City](team_name) match time\",\n",
        "        \"[Manchester United](team_name) contre [Manchester City](team_name) heure du match\",\n",
        "        \"[Leicester City](team_name) vs [Tottenham Hotspur](team_name) match time\",\n",
        "        \"[Leicester City](team_name) contre [Tottenham Hotspur](team_name) heure du match\",\n",
        "        \"Tell me when [Arsenal](team_name) will play with [Everton](team_name)\",\n",
        "        \"Dis-moi quand [Arsenal](team_name) jouera avec [Everton](team_name)\",\n",
        "        \"Will [Liverpool](team_name) play against [Chelsea](team_name)\",\n",
        "        \"Est-ce que [Liverpool](team_name) jouera contre [Chelsea](team_name)\",\n",
        "        \"[Manchester City](team_name) vs [West Ham United](team_name) match time\",\n",
        "        \"[Manchester City](team_name) contre [West Ham United](team_name) heure du match\",\n",
        "        \"[Aston Villa](team_name) vs [Leeds United](team_name) match time\",\n",
        "        \"[Aston Villa](team_name) contre [Leeds United](team_name) heure du match\",\n",
        "        \"What's the match time for [Crystal Palace](team_name) vs [Everton](team_name)\",\n",
        "        \"Quelle est l'heure du match pour [Crystal Palace](team_name) contre [Everton](team_name)\",\n",
        "        \"Any matches scheduled for [Wolverhampton Wanderers](team_name) and [Fulham](team_name)\",\n",
        "        \"Des matchs prévus pour [Wolverhampton Wanderers](team_name) et [Fulham](team_name)\",\n",
        "        \"When will be the match of [Leicester City](team_name) against [Arsenal](team_name)\",\n",
        "        \"Quand aura lieu le match de [Leicester City](team_name) contre [Arsenal](team_name)\",\n",
        "        \"[Tottenham Hotspur](team_name) vs [Chelsea](team_name) match time\",\n",
        "        \"[Tottenham Hotspur](team_name) contre [Chelsea](team_name) heure du match\",\n",
        "        \"[Southampton](team_name) vs [Manchester United](team_name) match time\",\n",
        "        \"[Southampton](team_name) contre [Manchester United](team_name) heure du match\",\n",
        "        \"Tell me when [Liverpool](team_name) will play with [Arsenal](team_name)\",\n",
        "        \"Dis-moi quand [Liverpool](team_name) jouera avec [Arsenal](team_name)\",\n",
        "        \"Will [Everton](team_name) play against [Tottenham Hotspur](team_name)\",\n",
        "        \"Est-ce que [Everton](team_name) jouera contre [Tottenham Hotspur](team_name)\",\n",
        "        \"[Manchester City](team_name) vs [Leicester City](team_name) match time\",\n",
        "        \"[Manchester City](team_name) contre [Leicester City](team_name) heure du match\",\n",
        "        \"[West Ham United](team_name) vs [Crystal Palace](team_name) match time\",\n",
        "        \"[West Ham United](team_name) contre [Crystal Palace](team_name) heure du match\",\n",
        "        \"What's the match time for [Manchester United](team_name) vs [Brighton and Hove Albion](team_name)\",\n",
        "        \"Quelle est l'heure du match pour [Manchester United](team_name) contre [Brighton and Hove Albion](team_name)\",\n",
        "        \"Any matches scheduled for [Chelsea](team_name) and [Fulham](team_name)\",\n",
        "        \"Des matchs prévus pour [Chelsea](team_name) et [Fulham](team_name)\",\n",
        "        \"When will be the match of [Liverpool](team_name) against [Manchester City](team_name)\",\n",
        "        \"Quand aura lieu le match de [Liverpool](team_name) contre [Manchester City](team_name)\",\n",
        "        \"[Arsenal](team_name) vs [Everton](team_name) match time\",\n",
        "        \"[Arsenal](team_name) contre [Everton](team_name) heure du match\",\n",
        "        \"[Tottenham Hotspur](team_name) vs [Leeds United](team_name) match time\",\n",
        "        \"[Tottenham Hotspur](team_name) contre [Leeds United](team_name) heure du match\",\n",
        "        \"Tell me when [Manchester United](team_name) will play with [West Ham United](team_name)\",\n",
        "        \"Dis-moi quand [Manchester United](team_name) jouera avec [West Ham United](team_name)\",\n",
        "        \"Will [Brighton and Hove Albion](team_name) play against [Crystal Palace](team_name)\",],\n",
        "\n",
        "    \"matches-match_result\": [\n",
        "        \"Who won in [Bournemouth](team_name) vs [West Ham United](team_name) match\",\n",
        "        \"Quel est le score du match [Manchester United](team_name)\",\n",
        "        \"Who won in [Norwich City](team_name) vs [Norwich City](team_name) match\",\n",
        "        \"Did [Everton](team_name) defeated [Leicester City](team_name)\",\n",
        "        \"Who won in [Leeds United](team_name) vs [Arsenal](team_name) match\",\n",
        "        \"Résultat final de [West Ham United](team_name) et [Crystal Palace](team_name)\",\n",
        "        \"Est-ce que [Brighton and Hove Albion](team_name) a vaincu [Watford](team_name)\",\n",
        "        \"[Wolverhampton](team_name) contre [Brighton and Hove Albion](team_name) heure du match\",\n",
        "        \"Quel est le score du match [Brentford](team_name)\",\n",
        "        \"Who won in [Liverpool](team_name) vs [Newcastle United](team_name) match\",\n",
        "        \"What is the score of [Manchester United](team_name) match\",\n",
        "        \"[Chelsea](team_name) and [Norwich](team_name) final result\",\n",
        "        \"Résultat de [Everton](team_name) et [Leeds United](team_name)\",\n",
        "        \"Score of [Everton](team_name) match\",\n",
        "        \"Who won in [Aston Villa](team_name) vs [Southampton](team_name) match\",\n",
        "        \"Résultat final de [Chelsea](team_name) et [Norwich](team_name)\",\n",
        "        \"[Leicester City](team_name) and [Brighton and Hove Albion](team_name) result\",\n",
        "        \"Quelle est l'heure du match pour [Fulham](team_name) contre [Burnley](team_name)\",\n",
        "        \"Did [Liverpool](team_name) defeated [Manchester City](team_name)\",\n",
        "        \"Est-ce que [Liverpool](team_name) a vaincu [man city] (team_name)\",\n",
        "        \"What is the score of [Arsenal](team_name) match\",\n",
        "        \"Résultat de [Liverpool](team_name) et [West Ham](team_name)\",\n",
        "        \"Résultat final de [Norwich City](team_name) et [Wolverhampton Wanderers](team_name)\",\n",
        "        \"Qui a gagné le match [Bournemouth](team_name) contre [West Ham United](team_name)\",\n",
        "        \"What is the score of [Wolverhampton](team_name) match\",\n",
        "        \"[Tottenham Hotspur](team_name) vs [Leeds United](team_name) match time\",\n",
        "        \"[Aston Villa](team_name) contre [Leeds United](team_name) heure du match\",\n",
        "        \"[Everton](team_name) and [Leeds United](team_name) result\",\n",
        "        \"Quel est le score du match [Wolverhampton](team_name)\",\n",
        "        \"Who won in [Manchester City](team_name) vs [Tottenham Hotspur](team_name) match\",\n",
        "        \"[Leeds United](team_name) vs [Manchester City](team_name) match time\",\n",
        "        \"Qui a gagné le match [Norwich City](team_name) contre [Norwich City](team_name)\",\n",
        "        \"Quelle est l'heure du match pour [Fulham](team_name) contre [Burnley](team_name)\",\n",
        "        \"What is the score of [Brentford](team_name) match\",\n",
        "        \"Quand aura lieu le match d'[Arsenal](team_name) contre [Manchester United](team_name)\",\n",
        "        \"Est-ce que [West Ham United](team_name) jouera contre [Leicester City](team_name)\",\n",
        "        \"What's the match time for [Fulham](team_name) vs [Burnley](team_name)\",\n",
        "        \"Who won in [Liverpool](team_name) vs [Newcastle United](team_name) match\",\n",
        "        \"Qui a gagné le match [Leicester City](team_name) contre [Arsenal](team_name)\",\n",
        "        \"Quand [Liverpool](team_name) jouera avec [Manchester City](team_name)\",\n",
        "        \"What is the score of [Wolverhampton](team_name) match\",\n",
        "        \"What's the match time for [Fulham](team_name) vs [Burnley](team_name)\",\n",
        "        \"What is the score of [Brentford](team_name) match\",\n",
        "        \"Quel est le score du match [Wolverhampton](team_name)\",\n",
        "        \"Quand [Liverpool](team_name) jouera avec [Manchester City](team_name)\",\n",
        "        \"What's the match time for [Fulham](team_name) vs [Burnley](team_name)\",\n",
        "        \"What is the score of [Brentford](team_name) match\",]\n",
        "    }\n"
      ],
      "metadata": {
        "id": "QDdDiUMxUu16"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "team_name_lookup = [\n",
        "    'Nottingham Forest',\n",
        "    'Manchester United',\n",
        "    'Blackpool',\n",
        "    'Birmingham City',\n",
        "    'Chelsea',\n",
        "    'West Ham',\n",
        "    'Wolverhampton Wanderers',\n",
        "    'Huddersfield Town U21',\n",
        "    'Charlton Athletic U21',\n",
        "    'QPR',\n",
        "    'Fulham U21',\n",
        "    'Blackburn Rovers',\n",
        "    'Newcastle United',\n",
        "    'SHU',\n",
        "    'Nottingham',\n",
        "    'Bournemouth',\n",
        "    'West Ham United',\n",
        "    'West Brom',\n",
        "    'Sheffield',\n",
        "    'Peterborough United U21',\n",
        "    'PET',\n",
        "    'Leeds',\n",
        "    'Arsenal',\n",
        "    'West Bromwich Albion U21',\n",
        "    'Derby County U21',\n",
        "    'Liverpool',\n",
        "    'Brentford',\n",
        "    'SCFC',\n",
        "    'Stoke City U21',\n",
        "    'Leeds United U21',\n",
        "    'Leicester City',\n",
        "    'Fulham',\n",
        "    'Wolverhampton',\n",
        "    'Charlton',\n",
        "    'NEW',\n",
        "    'Huddersfield Town',\n",
        "    'LEE',\n",
        "    'Newcastle United U21',\n",
        "    'Wigan Athletic U21',\n",
        "    'Sheffield United U21',\n",
        "    'man city',\n",
        "    'Bolton Wanderers',\n",
        "    'WOL',\n",
        "    'WBA',\n",
        "    'Stoke',\n",
        "    'Bradford City',\n",
        "    'Barnsley',\n",
        "    'Everton',\n",
        "    'Arsenal U21',\n",
        "    'FUL',\n",
        "    'Southampton',\n",
        "    'Aston Villa',\n",
        "    'Manchester City',\n",
        "    'WES',\n",
        "    'Leeds United',\n",
        "    'Tottenham Hotspur',\n",
        "    'WIG',\n",
        "    'Wolverhampton U21',\n",
        "    'MIB',\n",
        "    'Queens Park Rangers U21',\n",
        "    'Derby',\n",
        "    'Tottenham',\n",
        "    'ARS',\n",
        "    'West Ham United U21',\n",
        "    'Peterborough Utd',\n",
        "    'Wigan',\n",
        "    'DCO',\n",
        "    'Burnley',\n",
        "    'Middlesbrough',\n",
        "    'Newcastle',\n",
        "    'HTO',\n",
        "    'Middlesbrough U21',\n",
        "    'CHA',\n",
        "    'Crystal Palace'\n",
        "]\n"
      ],
      "metadata": {
        "id": "REe9uXE_wcKs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlu_data = []\n",
        "nlu_data.append('version: \"3.1\"')\n",
        "nlu_data.append('nlu:')\n",
        "\n",
        "for intent_name, examples in train_data.items():\n",
        "    nlu_data.append(f'- intent: {intent_name}')\n",
        "    nlu_data.append('  examples: |')\n",
        "\n",
        "    for example in examples:\n",
        "        if example.strip() == \"\":\n",
        "            continue\n",
        "\n",
        "        nlu_data.append(f'    - {example}')\n",
        "\n",
        "nlu_data.append('- lookup: team_name')\n",
        "nlu_data.append('  examples: |')\n",
        "\n",
        "for team_name in team_name_lookup:\n",
        "    nlu_data.append(f'    - {team_name}')\n",
        "\n",
        "# to format the nlu data"
      ],
      "metadata": {
        "id": "torjuUy-xL0s"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#type the content of the NLU data in a yaml file\n",
        "with open('./data.yml', 'w') as dest:\n",
        "    dest.write( \"\\n\".join( nlu_data ) )\n",
        ""
      ],
      "metadata": {
        "id": "_YvFGA4Uy64o"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#all of intent name must be collected in a file called domain.yaml\n",
        "domain_data = ['version: \"3.1\"','intents:']\n",
        "for intent_name, examples in train_data.items():\n",
        "    domain_data.append(f'  - {intent_name}')\n",
        "\n",
        "with open('./domain.yml', 'w') as dest:\n",
        "    dest.write( \"\\n\".join( domain_data ) )"
      ],
      "metadata": {
        "id": "Odi_F6Xg0jS5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = \"\"\"\n",
        "# The config recipe.\n",
        "# https://rasa.com/docs/rasa/model-configuration/\n",
        "recipe: default.v1\n",
        "language: en\n",
        "pipeline:\n",
        "- name: \"WhitespaceTokenizer\"\n",
        "- name: LanguageModelFeaturizer\n",
        "  model_weights: \"rasa/LaBSE\"\n",
        "  model_name: \"bert\"\n",
        "- name: CountVectorsFeaturizer\n",
        "  analyzer: char_wb\n",
        "  min_ngram: 1\n",
        "  max_ngram: 4\n",
        "- name: CountVectorsFeaturizer\n",
        "- name: DIETClassifier\n",
        "  epochs: 150\n",
        "  num_transformer_layers: 4\n",
        "  transformer_size: 256\n",
        "  use_masked_language_model: True\n",
        "  drop_rate: 0.05\n",
        "  weight_sparsity: 0.7\n",
        "  batch_size: [512, 512]\n",
        "  embedding_dimension: 60\n",
        "  hidden_layer_sizes:\n",
        "    text: [256, 128]\n",
        "\"\"\".strip()\n",
        "\n",
        "with open(f'./config.yml', 'w') as dest:\n",
        "    dest.write( config )"
      ],
      "metadata": {
        "id": "zQ9tB7kA2MGz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rasa train --data ./data.yml --config ./config.yml --domain ./domain.yml --out /content/models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHviorBv_xFO",
        "outputId": "daaa701e-5059-4f73-fb57-819dcc27406a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/rasa/core/tracker_store.py:1044: MovedIn20Warning: \u001b[31mDeprecated API features detected! These feature(s) are not compatible with SQLAlchemy 2.0. \u001b[32mTo prevent incompatible upgrades prior to updating applications, ensure requirements files are pinned to \"sqlalchemy<2.0\". \u001b[36mSet environment variable SQLALCHEMY_WARN_20=1 to show all deprecation warnings.  Set environment variable SQLALCHEMY_SILENCE_UBER_WARNING=1 to silence this message.\u001b[0m (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
            "  Base: DeclarativeMeta = declarative_base()\n",
            "\u001b(0lqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqk\u001b(B\n",
            "\u001b(0x\u001b(B Rasa Open Source reports anonymous usage telemetry to help improve the product \u001b(0x\u001b(B\n",
            "\u001b(0x\u001b(B for all its users.                                                             \u001b(0x\u001b(B\n",
            "\u001b(0x\u001b(B                                                                                \u001b(0x\u001b(B\n",
            "\u001b(0x\u001b(B If you'd like to opt-out, you can use `rasa telemetry disable`.                \u001b(0x\u001b(B\n",
            "\u001b(0x\u001b(B To learn more, check out https://rasa.com/docs/rasa/telemetry/telemetry.       \u001b(0x\u001b(B\n",
            "\u001b(0mqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqj\u001b(B\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API\n",
            "  warnings.warn(\"pkg_resources is deprecated as an API\", DeprecationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('ruamel')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "2024-04-26 20:02:49 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.cli.train\u001b[0m  - Started validating domain and training data...\n",
            "2024-04-26 20:02:51 \u001b[1;30mINFO    \u001b[0m \u001b[34mnumexpr.utils\u001b[0m  - NumExpr defaulting to 2 threads.\n",
            "2024-04-26 20:02:53 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.validator\u001b[0m  - Validating intents...\n",
            "\u001b[93m/usr/local/lib/python3.10/dist-packages/rasa/shared/utils/io.py:99: UserWarning: The intent 'Great-hi' is not used in any story or rule.\n",
            "\u001b[0m\u001b[93m/usr/local/lib/python3.10/dist-packages/rasa/shared/utils/io.py:99: UserWarning: The intent 'great-good_bye' is not used in any story or rule.\n",
            "\u001b[0m\u001b[93m/usr/local/lib/python3.10/dist-packages/rasa/shared/utils/io.py:99: UserWarning: The intent 'matches-match_result' is not used in any story or rule.\n",
            "\u001b[0m\u001b[93m/usr/local/lib/python3.10/dist-packages/rasa/shared/utils/io.py:99: UserWarning: The intent 'matches-match_time' is not used in any story or rule.\n",
            "\u001b[0m\u001b[93m/usr/local/lib/python3.10/dist-packages/rasa/shared/utils/io.py:99: UserWarning: The intent 'matches-team_next_match' is not used in any story or rule.\n",
            "\u001b[0m\u001b[93m/usr/local/lib/python3.10/dist-packages/rasa/shared/utils/io.py:99: UserWarning: The intent 'who_are_you' is not used in any story or rule.\n",
            "\u001b[0m2024-04-26 20:02:53 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.validator\u001b[0m  - Validating uniqueness of intents and stories...\n",
            "\u001b[93m/usr/local/lib/python3.10/dist-packages/rasa/shared/utils/io.py:99: UserWarning: The example 'Quand aura lieu le match d'Arsenal contre Manchester United' was found labeled with multiple different intents in the training data. Each annotated message should only appear with one intent. You should fix that conflict The example is labeled with: matches-match_result, matches-match_time.\n",
            "\u001b[0m\u001b[93m/usr/local/lib/python3.10/dist-packages/rasa/shared/utils/io.py:99: UserWarning: The example 'Leeds United vs Manchester City match time' was found labeled with multiple different intents in the training data. Each annotated message should only appear with one intent. You should fix that conflict The example is labeled with: matches-match_result, matches-match_time.\n",
            "\u001b[0m\u001b[93m/usr/local/lib/python3.10/dist-packages/rasa/shared/utils/io.py:99: UserWarning: The example 'Est-ce que West Ham United jouera contre Leicester City' was found labeled with multiple different intents in the training data. Each annotated message should only appear with one intent. You should fix that conflict The example is labeled with: matches-match_result, matches-match_time.\n",
            "\u001b[0m\u001b[93m/usr/local/lib/python3.10/dist-packages/rasa/shared/utils/io.py:99: UserWarning: The example 'What's the match time for Fulham vs Burnley' was found labeled with multiple different intents in the training data. Each annotated message should only appear with one intent. You should fix that conflict The example is labeled with: matches-match_result, matches-match_time.\n",
            "\u001b[0m\u001b[93m/usr/local/lib/python3.10/dist-packages/rasa/shared/utils/io.py:99: UserWarning: The example 'Quelle est l'heure du match pour Fulham contre Burnley' was found labeled with multiple different intents in the training data. Each annotated message should only appear with one intent. You should fix that conflict The example is labeled with: matches-match_result, matches-match_time.\n",
            "\u001b[0m\u001b[93m/usr/local/lib/python3.10/dist-packages/rasa/shared/utils/io.py:99: UserWarning: The example 'Aston Villa contre Leeds United heure du match' was found labeled with multiple different intents in the training data. Each annotated message should only appear with one intent. You should fix that conflict The example is labeled with: matches-match_result, matches-match_time.\n",
            "\u001b[0m\u001b[93m/usr/local/lib/python3.10/dist-packages/rasa/shared/utils/io.py:99: UserWarning: The example 'Tottenham Hotspur vs Leeds United match time' was found labeled with multiple different intents in the training data. Each annotated message should only appear with one intent. You should fix that conflict The example is labeled with: matches-match_result, matches-match_time.\n",
            "\u001b[0m2024-04-26 20:02:53 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.validator\u001b[0m  - Validating utterances...\n",
            "2024-04-26 20:02:53 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.validator\u001b[0m  - Story structure validation...\n",
            "2024-04-26 20:02:53 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.core.training.story_conflict\u001b[0m  - Considering all preceding turns for conflict analysis.\n",
            "2024-04-26 20:02:53 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.validator\u001b[0m  - No story structure conflicts found.\n",
            "\u001b[93mNo stories present. Just a Rasa NLU model will be trained.\u001b[0m\n",
            "\u001b[93m/usr/local/lib/python3.10/dist-packages/rasa/shared/utils/io.py:99: UserWarning: You have defined training data consisting of lookup tables, but your NLU configuration does not include a featurizer or an entity extractor using the lookup table.To use the lookup tables, include either a 'RegexFeaturizer' or a 'RegexEntityExtractor' in your configuration.\n",
            "  More info at https://rasa.com/docs/rasa/components\n",
            "vocab.txt: 100% 5.22M/5.22M [00:02<00:00, 2.02MB/s]\n",
            "special_tokens_map.json: 100% 112/112 [00:00<00:00, 475kB/s]\n",
            "tokenizer_config.json: 100% 277/277 [00:00<00:00, 1.37MB/s]\n",
            "config.json: 100% 654/654 [00:00<00:00, 3.03MB/s]\n",
            "tf_model.h5: 100% 1.88G/1.88G [00:15<00:00, 125MB/s]\n",
            "All model checkpoint layers were used when initializing TFBertModel.\n",
            "\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at rasa/LaBSE.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "2024-04-26 20:03:50 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Starting to train component 'CountVectorsFeaturizer'.\n",
            "2024-04-26 20:03:50 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.featurizers.sparse_featurizer.count_vectors_featurizer\u001b[0m  - 2470 vocabulary items were created for text attribute.\n",
            "2024-04-26 20:03:50 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Finished training component 'CountVectorsFeaturizer'.\n",
            "2024-04-26 20:03:51 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Starting to train component 'CountVectorsFeaturizer'.\n",
            "2024-04-26 20:03:51 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.featurizers.sparse_featurizer.count_vectors_featurizer\u001b[0m  - 330 vocabulary items were created for text attribute.\n",
            "2024-04-26 20:03:51 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Finished training component 'CountVectorsFeaturizer'.\n",
            "2024-04-26 20:03:52 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Starting to train component 'DIETClassifier'.\n",
            "\u001b[93m/usr/local/lib/python3.10/dist-packages/rasa/utils/train_utils.py:530: UserWarning: constrain_similarities is set to `False`. It is recommended to set it to `True` when using cross-entropy loss.\n",
            "  rasa.shared.utils.io.raise_warning(\n",
            "Epochs: 100% 150/150 [07:33<00:00,  3.02s/it, t_loss=3.15, m_acc=0.873, i_acc=0.983, e_f1=0.94]\n",
            "2024-04-26 20:11:27 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Finished training component 'DIETClassifier'.\n",
            "\u001b[92mYour Rasa model is trained and saved at '/content/models/nlu-20240426-200255-antique-colonnade.tar.gz'.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zcdt75TDCQOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#'/content/models/nlu-20240426-200255-antique-colonnade.tar.gz"
      ],
      "metadata": {
        "id": "UgRXgLA7CQrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from rasa.core.agent import Agent\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "I0xblSgjCSNZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cp = \"/content/models/nlu-20240426-200255-antique-colonnade.tar.gz\""
      ],
      "metadata": {
        "id": "kAaysdtnCgsy"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Agent.load(model_path=model_cp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AZZHMlFCloe",
        "outputId": "b5753e24-990f-4cd0-e5ec-13b0172d4460"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "All model checkpoint layers were used when initializing TFBertModel.\n",
            "\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at rasa/LaBSE.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "\u001b[93m/usr/local/lib/python3.10/dist-packages/rasa/utils/train_utils.py:530: UserWarning: constrain_similarities is set to `False`. It is recommended to set it to `True` when using cross-entropy loss.\n",
            "  rasa.shared.utils.io.raise_warning(\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "message  = \"when Tottenham Hotspur play again \"\n",
        "pred = asyncio.run(\n",
        "    model.parse_message(message_data= message)\n",
        "\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQBJmu1sCs6O",
        "outputId": "4f491739-dab9-400f-c020-ad378cc4d472"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-26 20:16:45 [debug    ] processor.message.parse        parse_data_entities=[{'entity': 'team_name', 'start': 5, 'end': 22, 'confidence_entity': 0.8774569630622864, 'value': 'Tottenham Hotspur', 'extractor': 'DIETClassifier'}] parse_data_intent={'name': 'matches-match_time', 'confidence': 0.6514504551887512} parse_data_text=when Tottenham Hotspur play again\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKOMYVlMC5Fr",
        "outputId": "68e28764-b6f6-49c2-9865-3293a921c160"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'when Tottenham Hotspur play again',\n",
              " 'intent': {'name': 'matches-match_time', 'confidence': 0.6514504551887512},\n",
              " 'entities': [{'entity': 'team_name',\n",
              "   'start': 5,\n",
              "   'end': 22,\n",
              "   'confidence_entity': 0.8774569630622864,\n",
              "   'value': 'Tottenham Hotspur',\n",
              "   'extractor': 'DIETClassifier'}],\n",
              " 'text_tokens': [(0, 4), (5, 14), (15, 22), (23, 27), (28, 33)],\n",
              " 'intent_ranking': [{'name': 'matches-match_time',\n",
              "   'confidence': 0.6514504551887512},\n",
              "  {'name': 'matches-team_next_match', 'confidence': 0.3387370705604553},\n",
              "  {'name': 'who_are_you', 'confidence': 0.0030447943136096},\n",
              "  {'name': 'matches-match_result', 'confidence': 0.0025027100928127766},\n",
              "  {'name': 'Great-hi', 'confidence': 0.002380614634603262},\n",
              "  {'name': 'great-good_bye', 'confidence': 0.0018843063153326511}]}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}